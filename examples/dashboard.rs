#![deny(unsafe_code)]

#[cfg(not(feature = "render-tui"))]
compile_error!(
    "The `render-tui` feature must be set, along with either `render-tui-crossterm` or `render-tui-termion`"
);
#[cfg(not(any(feature = "render-tui-crossterm", feature = "render-tui-termion")))]
compile_error!(
    "Please set either the 'render-tui-crossterm' or 'render-tui-termion' feature whne using the 'render-tui'"
);

fn main() -> Result {
    env_logger::init();

    let args: args::Options = argh::from_env();
    futures_lite::future::block_on(work_forever(args))
}

async fn work_forever(mut args: args::Options) -> Result {
    let progress = prodash::TreeOptions {
        message_buffer_capacity: args.message_scrollback_buffer_size,
        ..prodash::TreeOptions::default()
    }
    .create();
    {
        let mut sp = progress.add_child("preparation");
        sp.info("warming up");
        smol::Task::spawn(async move {
            async_io::Timer::after(Duration::from_millis(500)).await;
            sp.fail("engine failure");
            async_io::Timer::after(Duration::from_millis(750)).await;
            sp.done("warmup complete");
        })
        .detach();
    }
    // Now we should handle signals to be able to cleanup properly
    let speed = args.speed_multitplier;
    let changing_names = args.changing_names;

    let renderer = args.renderer.take().unwrap_or_else(|| "tui".into());
    let work_min = args.pooled_work_min;
    let work_max = args.pooled_work_max;
    let mut gui_handle = if renderer == "log" {
        let never_ending = smol::Task::spawn(futures_lite::future::pending::<()>());
        Some(never_ending.boxed())
    } else {
        Some(
            shared::launch_ambient_gui(progress.clone(), &renderer, args, false)
                .unwrap()
                .boxed(),
        )
    };

    loop {
        let local_work = new_chunk_of_work(
            NestingLevel(thread_rng().gen_range(0..=Key::max_level())),
            progress.clone(),
            speed,
            changing_names,
        )
        .boxed_local();
        let num_chunks = if work_min < work_max {
            thread_rng().gen_range(work_min..=work_max)
        } else {
            work_min
        };
        let pooled_work = (0..num_chunks).map(|_| {
            smol::Task::spawn(new_chunk_of_work(
                NestingLevel(thread_rng().gen_range(0..=Key::max_level())),
                progress.clone(),
                speed,
                changing_names,
            ))
            .boxed_local()
        });

        match futures_util::future::select(
            join_all(std::iter::once(local_work).chain(pooled_work)),
            gui_handle.take().expect("gui handle"),
        )
        .await
        {
            Either::Left((_workblock_result, running_gui)) => {
                gui_handle = Some(running_gui);
                continue;
            }
            Either::Right(_gui_shutdown) => break,
        }
    }

    if let Some(gui) = gui_handle {
        // gui.cancel();
        gui.await;
    }
    Ok(())
}

async fn work_item(mut progress: Item, speed: f32, changing_names: bool) {
    let max: u8 = thread_rng().gen_range(25..=125);
    progress.init(
        if max > WORK_STEPS_NEEDED_FOR_UNBOUNDED_TASK {
            None
        } else {
            Some(max.into())
        },
        if (max as usize % UNITS.len() + 1) == 0 {
            None
        } else {
            UNITS.choose(&mut thread_rng()).copied().map(Into::into)
        },
    );

    for step in 0..max {
        progress.set(step as Step);
        let delay_ms = if thread_rng().gen_bool(CHANCE_TO_BLOCK_PER_STEP) {
            let eta = if thread_rng().gen_bool(CHANCE_TO_SHOW_ETA) {
                Some(SystemTime::now().add(Duration::from_millis(LONG_WORK_DELAY_MS)))
            } else {
                None
            };
            if thread_rng().gen_bool(0.5) {
                progress.halted(REASONS.choose(&mut thread_rng()).unwrap(), eta);
            } else {
                progress.blocked(REASONS.choose(&mut thread_rng()).unwrap(), eta);
            }
            thread_rng().gen_range(WORK_DELAY_MS..=LONG_WORK_DELAY_MS)
        } else {
            thread_rng().gen_range(SHORT_DELAY_MS..=WORK_DELAY_MS)
        };
        if thread_rng().gen_bool(0.01) {
            progress.init(
                Some(max.into()),
                UNITS.choose(&mut thread_rng()).copied().map(Into::into),
            )
        }
        if thread_rng().gen_bool(0.01) {
            progress.info(*INFO_MESSAGES.choose(&mut thread_rng()).unwrap());
        }
        if thread_rng().gen_bool(if changing_names { 0.5 } else { 0.01 }) {
            progress.set_name(WORK_NAMES.choose(&mut thread_rng()).unwrap().to_string());
        }
        async_io::Timer::after(Duration::from_millis((delay_ms as f32 / speed) as u64)).await;
    }
    if thread_rng().gen_bool(0.95) {
        progress.done(*DONE_MESSAGES.choose(&mut thread_rng()).unwrap());
    } else {
        progress.fail(*FAIL_MESSAGES.choose(&mut thread_rng()).unwrap());
    }
}

async fn new_chunk_of_work(max: NestingLevel, tree: Tree, speed: f32, changing_names: bool) -> Result {
    let NestingLevel(max_level) = max;
    let mut progresses = Vec::new();
    let mut level_progress = tree.add_child(format!("level {} of {}", 1, max_level));
    let mut handles = Vec::new();

    for level in 0..max_level {
        // one-off ambient tasks
        let num_tasks = max_level as usize * 2;
        for id in 0..num_tasks {
            let handle = smol::Task::spawn(work_item(
                level_progress.add_child(format!("{} {}", WORK_NAMES.choose(&mut thread_rng()).unwrap(), id + 1)),
                speed,
                changing_names,
            ));
            handles.push(handle);

            async_io::Timer::after(Duration::from_millis((SPAWN_DELAY_MS as f32 / speed) as u64)).await;
        }
        if level + 1 != max_level {
            let tmp = level_progress.add_child(format!("Level {}", level + 1));
            progresses.push(level_progress);
            level_progress = tmp;
        }
    }

    progresses.push(level_progress);
    for handle in handles.into_iter() {
        handle.await;
    }

    Ok(())
}

struct NestingLevel(u8);
type Result = std::result::Result<(), Box<dyn Error + Send>>;

use futures_util::{future::join_all, future::Either, FutureExt};
use prodash::{
    progress::{Key, Step},
    tree::Item,
    Tree,
};
use rand::prelude::*;
use std::{
    error::Error,
    ops::Add,
    time::{Duration, SystemTime},
};

const WORK_STEPS_NEEDED_FOR_UNBOUNDED_TASK: u8 = 100;
const UNITS: &[&str] = &["Mb", "kb", "items", "files"];
const REASONS: &[&str] = &["due to star alignment", "IO takes time", "ä»ªè¡¨æ¿æ¼”ç¤º", "just because"];
const WORK_NAMES: &[&str] = &[
    "Downloading Crate",
    "ä¸‹è½½æ¿æ¡ç®±",
    "Running 'cargo geiger'",
    "è¿è¡Œç¨‹åº 'cargo geiger'",
    "Counting lines of code",
    "è®¡æ•°ä»£ç è¡Œ",
    "Checking for unused dependencies",
    "æ£€æŸ¥æœªä½¿ç”¨çš„ä¾èµ–é¡¹",
    "Checking for crate-bloat",
    "æ£€æŸ¥æ¿æ¡ç®±è†¨èƒ€",
    "Generating report",
    "ç”ŸæˆæŠ¥å‘Š",
];
const DONE_MESSAGES: &[&str] = &[
    "Yeeeehaa! Finally!!",
    "å‘€ï¼ æœ€åï¼",
    "It feels good to be done!",
    "æ„Ÿè§‰å¥½æäº†ï¼",
    "Told you so!!",
    "å‘Šè¯‰è¿‡ä½ äº†ï¼",
];
const FAIL_MESSAGES: &[&str] = &[
    "That didn't seem to work!",
    "é‚£ä¼¼ä¹æ²¡æœ‰ç”¨ï¼",
    "Oh myâ€¦ I failed you ğŸ˜",
    "å“¦ï¼Œæˆ‘â€¦æˆ‘è®©ä½ å¤±è´¥ğŸ˜",
    "This didn't end wellâ€¦",
    "ç»“å±€ä¸å¥½â€¦",
];
const INFO_MESSAGES: &[&str] = &[
    "Making good progress!",
    "è¿›å±•è‰¯å¥½ï¼",
    "Humming alongâ€¦",
    "å—¡å—¡ä½œå“â€¦",
    "It will be done soooooonâ€¦",
    "ä¼šå¾ˆå¿«å®Œæˆçš„â€¦â€¦",
];
const SHORT_DELAY_MS: u64 = 50;
const WORK_DELAY_MS: u64 = 100;
const LONG_WORK_DELAY_MS: u64 = 2000;
const SPAWN_DELAY_MS: u64 = 200;
const CHANCE_TO_BLOCK_PER_STEP: f64 = 1.0 / 100.0;
const CHANCE_TO_SHOW_ETA: f64 = 0.5;

mod shared;
use shared::args;
use shared::smol;
